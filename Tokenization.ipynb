{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIrtWo/XxXw/K9HVntk4Lm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryJonesBaluguri/MachineLearning/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfB3FJXMDvXd",
        "outputId": "3561b4fd-e5bc-432c-b405-ff7e69591a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "xyLhoFvdFgDo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Ds_7LEFjRr",
        "outputId": "0dffeb6c-cfdf-49ed-f2f2-b42e0f28db87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"\"\"Choose spaCy for production, performance-critical applications, as it is fast, efficient, and offers pre-trained models for industrial use cases.\n",
        "Opt for NLTK for learning, research, or detailed linguistic analysis.\n",
        "NLTK provides a wide range of algorithms and granular control for exploring NLP mechanics,\n",
        "while spaCy focuses on speed, scalability, and ease of integration with deep learning models for real-world applications\"\"\""
      ],
      "metadata": {
        "id": "t76iIHf1EGmu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "cr4aFQaAEG11",
        "outputId": "19a07309-7e29-4b94-a6fe-8504ddc793e9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Choose spaCy for production, performance-critical applications, as it is fast, efficient, and offers pre-trained models for industrial use cases.\\nOpt for NLTK for learning, research, or detailed linguistic analysis.\\nNLTK provides a wide range of algorithms and granular control for exploring NLP mechanics,\\nwhile spaCy focuses on speed, scalability, and ease of integration with deep learning models for real-world applications'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7Z2mmOwEHCl",
        "outputId": "3cb7b1b0-f415-4ff1-d176-4fb90ae31bf5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose spaCy for production, performance-critical applications, as it is fast, efficient, and offers pre-trained models for industrial use cases.\n",
            "Opt for NLTK for learning, research, or detailed linguistic analysis.\n",
            "NLTK provides a wide range of algorithms and granular control for exploring NLP mechanics,\n",
            "while spaCy focuses on speed, scalability, and ease of integration with deep learning models for real-world applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "j-Vt2uELFJoh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize=sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "_AA5MUDjFJr8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8FJUSRuFJ2K",
        "outputId": "6e4b9e77-31de-4973-85b4-d2d726ae4e5b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Choose spaCy for production, performance-critical applications, as it is fast, efficient, and offers pre-trained models for industrial use cases.', 'Opt for NLTK for learning, research, or detailed linguistic analysis.', 'NLTK provides a wide range of algorithms and granular control for exploring NLP mechanics,\\nwhile spaCy focuses on speed, scalability, and ease of integration with deep learning models for real-world applications']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tokenize))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSof3q4FJ5w",
        "outputId": "9d951030-4a26-43ad-b7a8-112e19559bd3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "2HpJkccbF2HH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordtokens=word_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "mPR4kiQoF2T0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in wordtokens:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRGKBsrpG7rA",
        "outputId": "7acca2b1-1c0d-497d-c534-691fd43659ec"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose\n",
            "spaCy\n",
            "for\n",
            "production\n",
            ",\n",
            "performance-critical\n",
            "applications\n",
            ",\n",
            "as\n",
            "it\n",
            "is\n",
            "fast\n",
            ",\n",
            "efficient\n",
            ",\n",
            "and\n",
            "offers\n",
            "pre-trained\n",
            "models\n",
            "for\n",
            "industrial\n",
            "use\n",
            "cases\n",
            ".\n",
            "Opt\n",
            "for\n",
            "NLTK\n",
            "for\n",
            "learning\n",
            ",\n",
            "research\n",
            ",\n",
            "or\n",
            "detailed\n",
            "linguistic\n",
            "analysis\n",
            ".\n",
            "NLTK\n",
            "provides\n",
            "a\n",
            "wide\n",
            "range\n",
            "of\n",
            "algorithms\n",
            "and\n",
            "granular\n",
            "control\n",
            "for\n",
            "exploring\n",
            "NLP\n",
            "mechanics\n",
            ",\n",
            "while\n",
            "spaCy\n",
            "focuses\n",
            "on\n",
            "speed\n",
            ",\n",
            "scalability\n",
            ",\n",
            "and\n",
            "ease\n",
            "of\n",
            "integration\n",
            "with\n",
            "deep\n",
            "learning\n",
            "models\n",
            "for\n",
            "real-world\n",
            "applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "Hq9XMTKCW7YB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=wordpunct_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "J8_H1kaqW8Hq"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIwv1OqmXMpY",
        "outputId": "fdd121af-d45a-4370-d799-2803fb253399"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Choose', 'spaCy', 'for', 'production', ',', 'performance', '-', 'critical', 'applications', ',', 'as', 'it', 'is', 'fast', ',', 'efficient', ',', 'and', 'offers', 'pre', '-', 'trained', 'models', 'for', 'industrial', 'use', 'cases', '.', 'Opt', 'for', 'NLTK', 'for', 'learning', ',', 'research', ',', 'or', 'detailed', 'linguistic', 'analysis', '.', 'NLTK', 'provides', 'a', 'wide', 'range', 'of', 'algorithms', 'and', 'granular', 'control', 'for', 'exploring', 'NLP', 'mechanics', ',', 'while', 'spaCy', 'focuses', 'on', 'speed', ',', 'scalability', ',', 'and', 'ease', 'of', 'integration', 'with', 'deep', 'learning', 'models', 'for', 'real', '-', 'world', 'applications']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "J5EowUGTXRoH"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tbtokens=TreebankWordTokenizer()\n",
        "tokenstb=tbtokens.tokenize(paragraph)"
      ],
      "metadata": {
        "id": "pbCv5s6JXR0g"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenstb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ZzTP3zXR4D",
        "outputId": "8e676176-8cda-4c01-ccea-ed11b59e54f8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Choose',\n",
              " 'spaCy',\n",
              " 'for',\n",
              " 'production',\n",
              " ',',\n",
              " 'performance-critical',\n",
              " 'applications',\n",
              " ',',\n",
              " 'as',\n",
              " 'it',\n",
              " 'is',\n",
              " 'fast',\n",
              " ',',\n",
              " 'efficient',\n",
              " ',',\n",
              " 'and',\n",
              " 'offers',\n",
              " 'pre-trained',\n",
              " 'models',\n",
              " 'for',\n",
              " 'industrial',\n",
              " 'use',\n",
              " 'cases.',\n",
              " 'Opt',\n",
              " 'for',\n",
              " 'NLTK',\n",
              " 'for',\n",
              " 'learning',\n",
              " ',',\n",
              " 'research',\n",
              " ',',\n",
              " 'or',\n",
              " 'detailed',\n",
              " 'linguistic',\n",
              " 'analysis.',\n",
              " 'NLTK',\n",
              " 'provides',\n",
              " 'a',\n",
              " 'wide',\n",
              " 'range',\n",
              " 'of',\n",
              " 'algorithms',\n",
              " 'and',\n",
              " 'granular',\n",
              " 'control',\n",
              " 'for',\n",
              " 'exploring',\n",
              " 'NLP',\n",
              " 'mechanics',\n",
              " ',',\n",
              " 'while',\n",
              " 'spaCy',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'speed',\n",
              " ',',\n",
              " 'scalability',\n",
              " ',',\n",
              " 'and',\n",
              " 'ease',\n",
              " 'of',\n",
              " 'integration',\n",
              " 'with',\n",
              " 'deep',\n",
              " 'learning',\n",
              " 'models',\n",
              " 'for',\n",
              " 'real-world',\n",
              " 'applications']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "TZcavJPAG75p"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming=PorterStemmer()"
      ],
      "metadata": {
        "id": "taUGzHebISLQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemming.stem(\"Playing\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6K4NPxAISN2",
        "outputId": "35725757-66e8-4eab-99ad-7ff731b8e200"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in wordtokens:\n",
        "  print(word+\"--->\"+stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNQin4Q7ISQn",
        "outputId": "8eec7ad2-8e81-48b9-8ad6-605f64736b61"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose--->choos\n",
            "spaCy--->spaci\n",
            "for--->for\n",
            "production--->product\n",
            ",--->,\n",
            "performance-critical--->performance-crit\n",
            "applications--->applic\n",
            ",--->,\n",
            "as--->as\n",
            "it--->it\n",
            "is--->is\n",
            "fast--->fast\n",
            ",--->,\n",
            "efficient--->effici\n",
            ",--->,\n",
            "and--->and\n",
            "offers--->offer\n",
            "pre-trained--->pre-train\n",
            "models--->model\n",
            "for--->for\n",
            "industrial--->industri\n",
            "use--->use\n",
            "cases--->case\n",
            ".--->.\n",
            "Opt--->opt\n",
            "for--->for\n",
            "NLTK--->nltk\n",
            "for--->for\n",
            "learning--->learn\n",
            ",--->,\n",
            "research--->research\n",
            ",--->,\n",
            "or--->or\n",
            "detailed--->detail\n",
            "linguistic--->linguist\n",
            "analysis--->analysi\n",
            ".--->.\n",
            "NLTK--->nltk\n",
            "provides--->provid\n",
            "a--->a\n",
            "wide--->wide\n",
            "range--->rang\n",
            "of--->of\n",
            "algorithms--->algorithm\n",
            "and--->and\n",
            "granular--->granular\n",
            "control--->control\n",
            "for--->for\n",
            "exploring--->explor\n",
            "NLP--->nlp\n",
            "mechanics--->mechan\n",
            ",--->,\n",
            "while--->while\n",
            "spaCy--->spaci\n",
            "focuses--->focus\n",
            "on--->on\n",
            "speed--->speed\n",
            ",--->,\n",
            "scalability--->scalabl\n",
            ",--->,\n",
            "and--->and\n",
            "ease--->eas\n",
            "of--->of\n",
            "integration--->integr\n",
            "with--->with\n",
            "deep--->deep\n",
            "learning--->learn\n",
            "models--->model\n",
            "for--->for\n",
            "real-world--->real-world\n",
            "applications--->applic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "PuBj3UKAISTs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_exp_stem=RegexpStemmer(r'(ing$|able$|s$|es$)',min=4)"
      ],
      "metadata": {
        "id": "Perq2FFrR6hr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_exp_stem.stem(\"playing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y4NO6OITR6v1",
        "outputId": "3b5ade30-de68-40f9-be2c-fc81b34ed79a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_exp_stem.stem(\"players\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RX8txTZnISXL",
        "outputId": "7920cd41-5b9c-4aa6-98ed-e4575cb81491"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'player'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "hoy6zdJVVLgt"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowstem=SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "9iJI7wVsVLkB"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowstem.stem(\"Fairly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kcARk58QVLvL",
        "outputId": "c9815117-e9a1-4a1a-8d21-963b1127be66"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fair'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"Fairly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BTUkrBoQVLyl",
        "outputId": "5cfdddae-e4bf-442e-d953-7489aef434d7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fairli'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in wordtokens:\n",
        "  print(word+\"--->\"+snowstem.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJs4c_b5Wh69",
        "outputId": "0e482d39-d585-4ea5-91c3-07244491ea96"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose--->choos\n",
            "spaCy--->spaci\n",
            "for--->for\n",
            "production--->product\n",
            ",--->,\n",
            "performance-critical--->performance-crit\n",
            "applications--->applic\n",
            ",--->,\n",
            "as--->as\n",
            "it--->it\n",
            "is--->is\n",
            "fast--->fast\n",
            ",--->,\n",
            "efficient--->effici\n",
            ",--->,\n",
            "and--->and\n",
            "offers--->offer\n",
            "pre-trained--->pre-train\n",
            "models--->model\n",
            "for--->for\n",
            "industrial--->industri\n",
            "use--->use\n",
            "cases--->case\n",
            ".--->.\n",
            "Opt--->opt\n",
            "for--->for\n",
            "NLTK--->nltk\n",
            "for--->for\n",
            "learning--->learn\n",
            ",--->,\n",
            "research--->research\n",
            ",--->,\n",
            "or--->or\n",
            "detailed--->detail\n",
            "linguistic--->linguist\n",
            "analysis--->analysi\n",
            ".--->.\n",
            "NLTK--->nltk\n",
            "provides--->provid\n",
            "a--->a\n",
            "wide--->wide\n",
            "range--->rang\n",
            "of--->of\n",
            "algorithms--->algorithm\n",
            "and--->and\n",
            "granular--->granular\n",
            "control--->control\n",
            "for--->for\n",
            "exploring--->explor\n",
            "NLP--->nlp\n",
            "mechanics--->mechan\n",
            ",--->,\n",
            "while--->while\n",
            "spaCy--->spaci\n",
            "focuses--->focus\n",
            "on--->on\n",
            "speed--->speed\n",
            ",--->,\n",
            "scalability--->scalabl\n",
            ",--->,\n",
            "and--->and\n",
            "ease--->eas\n",
            "of--->of\n",
            "integration--->integr\n",
            "with--->with\n",
            "deep--->deep\n",
            "learning--->learn\n",
            "models--->model\n",
            "for--->for\n",
            "real-world--->real-world\n",
            "applications--->applic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokens:\n",
        "  print(word+\"-->\"+snowstem.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiUs8mozWiKD",
        "outputId": "d1e34aa8-eab7-4f37-a38d-d9aa25570df9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose-->choos\n",
            "spaCy-->spaci\n",
            "for-->for\n",
            "production-->product\n",
            ",-->,\n",
            "performance-->perform\n",
            "--->-\n",
            "critical-->critic\n",
            "applications-->applic\n",
            ",-->,\n",
            "as-->as\n",
            "it-->it\n",
            "is-->is\n",
            "fast-->fast\n",
            ",-->,\n",
            "efficient-->effici\n",
            ",-->,\n",
            "and-->and\n",
            "offers-->offer\n",
            "pre-->pre\n",
            "--->-\n",
            "trained-->train\n",
            "models-->model\n",
            "for-->for\n",
            "industrial-->industri\n",
            "use-->use\n",
            "cases-->case\n",
            ".-->.\n",
            "Opt-->opt\n",
            "for-->for\n",
            "NLTK-->nltk\n",
            "for-->for\n",
            "learning-->learn\n",
            ",-->,\n",
            "research-->research\n",
            ",-->,\n",
            "or-->or\n",
            "detailed-->detail\n",
            "linguistic-->linguist\n",
            "analysis-->analysi\n",
            ".-->.\n",
            "NLTK-->nltk\n",
            "provides-->provid\n",
            "a-->a\n",
            "wide-->wide\n",
            "range-->rang\n",
            "of-->of\n",
            "algorithms-->algorithm\n",
            "and-->and\n",
            "granular-->granular\n",
            "control-->control\n",
            "for-->for\n",
            "exploring-->explor\n",
            "NLP-->nlp\n",
            "mechanics-->mechan\n",
            ",-->,\n",
            "while-->while\n",
            "spaCy-->spaci\n",
            "focuses-->focus\n",
            "on-->on\n",
            "speed-->speed\n",
            ",-->,\n",
            "scalability-->scalabl\n",
            ",-->,\n",
            "and-->and\n",
            "ease-->eas\n",
            "of-->of\n",
            "integration-->integr\n",
            "with-->with\n",
            "deep-->deep\n",
            "learning-->learn\n",
            "models-->model\n",
            "for-->for\n",
            "real-->real\n",
            "--->-\n",
            "world-->world\n",
            "applications-->applic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "y9aOWxhWYEUH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wdjgYK0Ycd0",
        "outputId": "d1ffd125-e2fa-43b6-f141-f733daea369d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnl=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Ne8P3AJmYEkZ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnl.lemmatize(\"eating\",'v') #v -verb\n",
        "#n-noun\n",
        "#a-adjective\n",
        "#r-adverb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2ke4O8OJYEv4",
        "outputId": "b5708c83-f344-4f19-fb15-111d5d2fa053"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in wordtokens:\n",
        "  print(word+\"-->\"+wnl.lemmatize(word,'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FY36cPnYE6m",
        "outputId": "0da03713-ed7e-414d-fd0b-677ded97665c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose-->Choose\n",
            "spaCy-->spaCy\n",
            "for-->for\n",
            "production-->production\n",
            ",-->,\n",
            "performance-critical-->performance-critical\n",
            "applications-->applications\n",
            ",-->,\n",
            "as-->as\n",
            "it-->it\n",
            "is-->be\n",
            "fast-->fast\n",
            ",-->,\n",
            "efficient-->efficient\n",
            ",-->,\n",
            "and-->and\n",
            "offers-->offer\n",
            "pre-trained-->pre-trained\n",
            "models-->model\n",
            "for-->for\n",
            "industrial-->industrial\n",
            "use-->use\n",
            "cases-->case\n",
            ".-->.\n",
            "Opt-->Opt\n",
            "for-->for\n",
            "NLTK-->NLTK\n",
            "for-->for\n",
            "learning-->learn\n",
            ",-->,\n",
            "research-->research\n",
            ",-->,\n",
            "or-->or\n",
            "detailed-->detail\n",
            "linguistic-->linguistic\n",
            "analysis-->analysis\n",
            ".-->.\n",
            "NLTK-->NLTK\n",
            "provides-->provide\n",
            "a-->a\n",
            "wide-->wide\n",
            "range-->range\n",
            "of-->of\n",
            "algorithms-->algorithms\n",
            "and-->and\n",
            "granular-->granular\n",
            "control-->control\n",
            "for-->for\n",
            "exploring-->explore\n",
            "NLP-->NLP\n",
            "mechanics-->mechanics\n",
            ",-->,\n",
            "while-->while\n",
            "spaCy-->spaCy\n",
            "focuses-->focus\n",
            "on-->on\n",
            "speed-->speed\n",
            ",-->,\n",
            "scalability-->scalability\n",
            ",-->,\n",
            "and-->and\n",
            "ease-->ease\n",
            "of-->of\n",
            "integration-->integration\n",
            "with-->with\n",
            "deep-->deep\n",
            "learning-->learn\n",
            "models-->model\n",
            "for-->for\n",
            "real-world-->real-world\n",
            "applications-->applications\n"
          ]
        }
      ]
    }
  ]
}